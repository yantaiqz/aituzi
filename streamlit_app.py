import streamlit as st
import google.generativeai as genai
from zhipuai import ZhipuAI
import PyPDF2
from docx import Document
from PIL import Image
import io
import json
import time

# -------------------------------------------------------------
# 1. é¡µé¢é…ç½®ä¸ CSS æ ·å¼ï¼ˆç§»é™¤ä¾§è¾¹æ ç›¸å…³æ ·å¼ï¼Œä¼˜åŒ–ä¸»é¡µé¢å¸ƒå±€ï¼‰
# -------------------------------------------------------------
st.set_page_config(
    page_title="AIå…”å­ å†…å®¹ä¸å‰½çªƒæ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ°",
    layout="wide",
    initial_sidebar_state="collapsed"  # å¼ºåˆ¶æŠ˜å ä¾§è¾¹æ 
)

# è‡ªå®šä¹‰ CSS ç¾åŒ–ç•Œé¢
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 20px;
        font-weight: 700;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #555;
        text-align: center;
        margin-bottom: 40px;
    }
    .result-card {
        background-color: #f8f9fa;
        border: 1px solid #ddd;
        border-radius: 10px;
        padding: 20px;
        margin-bottom: 20px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }
    .metric-label {
        font-weight: bold;
        color: #333;
    }
    .stProgress > div > div > div > div {
        background-image: linear-gradient(to right, #4caf50, #ffeb3b, #f44336);
    }
    .warning-text {
        color: #e65100;
        font-size: 0.9rem;
        font-style: italic;
    }
    .model-config-card {
        background-color: #e8f4f8;
        border-radius: 10px;
        padding: 20px;
        margin-bottom: 30px;
        border-left: 4px solid #1E88E5;
    }
    .stRadio > div {
        flex-direction: row;
        gap: 20px;
        justify-content: center;
    }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------
# 2. æ ¸å¿ƒåˆ†æé€»è¾‘ä¸ Prompt
# -------------------------------------------------------------
ANALYSIS_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ³•åŒ»è¯­è¨€å­¦å®¶å’Œå­¦æœ¯è¯šä¿¡ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æä¾›çš„æ–‡æœ¬ï¼ˆæˆ–å›¾ç‰‡ä¸­çš„æ–‡å­—ï¼‰ï¼Œå®Œæˆä»¥ä¸‹ä¸¤ä¸ªæ ¸å¿ƒä»»åŠ¡ï¼š

1. **AI ç”Ÿæˆæ£€æµ‹**ï¼šåˆ¤æ–­æ–‡æœ¬æ˜¯å¦ç”± AI ç”Ÿæˆã€‚åˆ†æè¡Œæ–‡é€»è¾‘ã€è¯æ±‡é‡å¤åº¦ã€æƒ…æ„Ÿè¿è´¯æ€§ã€å¹»è§‰ç‰¹å¾ç­‰ã€‚
    - åˆ†ç±»æ ‡å‡†ï¼š
      - "AIç‰¹å¾" (80%-100%): æé«˜æ¦‚ç‡ç”± AI ç”Ÿæˆã€‚
      - "ç–‘ä¼¼AI" (40%-79%): æ··åˆç‰¹å¾ï¼Œæ— æ³•ç¡®å®šï¼Œä½†æœ‰æ˜æ˜¾ AI ç—•è¿¹ã€‚
      - "äººå·¥ç‰¹å¾" (0%-39%): å…·æœ‰å…¸å‹çš„äººç±»å†™ä½œç‰¹å¾ï¼ˆå¦‚ä¸ªäººç»å†ã€éæ ‡å‡†è¯­æ³•ã€æƒ…æ„Ÿç»†å¾®å·®åˆ«ï¼‰ã€‚

2. **å‰½çªƒ/æŠ„è¢­æ£€æµ‹**ï¼šåˆ¤æ–­æ–‡æœ¬æ˜¯å¦å­˜åœ¨æŠ„è¢­å«Œç–‘ã€‚
    - åŸºäºä½ çš„è®­ç»ƒæ•°æ®ï¼Œåˆ†ææ–‡æœ¬æ˜¯å¦ä¸çŸ¥åæ–‡ç« ã€è®ºæ–‡ã€ç½‘ç»œå†…å®¹é«˜åº¦é›·åŒã€‚
    - å¦‚æœå‘ç°æŠ„è¢­ï¼Œè¯·æŒ‡å‡ºå¯èƒ½çš„æ¥æºã€‚

è¯·åŠ¡å¿…ä»¥ä¸¥æ ¼çš„ **JSON æ ¼å¼**è¿”å›ç»“æœï¼Œä¸è¦åŒ…å« Markdown ä»£ç å—æ ‡è®°ï¼ˆ```json ... ```ï¼‰ï¼Œç›´æ¥è¿”å› JSON å­—ç¬¦ä¸²ã€‚æ ¼å¼å¦‚ä¸‹ï¼š

{
    "ai_detection": {
        "label": "AIç‰¹å¾" | "ç–‘ä¼¼AI" | "äººå·¥ç‰¹å¾",
        "score": 0-100,
        "reason": "è¯¦ç»†çš„åˆ†æç†ç”±ï¼Œåˆ—å‡ºå…·ä½“çš„ç‰¹å¾ç‚¹ï¼ˆå¦‚ï¼šè¿‡åº¦ä½¿ç”¨è¿æ¥è¯ã€ç¼ºä¹å…·ä½“ç»†èŠ‚ã€é€»è¾‘è¿‡äºå®Œç¾ç­‰ï¼‰ã€‚"
    },
    "plagiarism_detection": {
        "percentage": 0-100,
        "reason": "è¯¦ç»†çš„åˆ†æç†ç”±ã€‚",
        "sources": "åˆ—å‡ºå¯èƒ½çš„åŸæ–‡æ¥æºï¼Œå¦‚æœæ²¡æœ‰å‘ç°æ˜æ˜¾æ¥æºï¼Œè¯·å¡«'æœªåœ¨è®­ç»ƒæ•°æ®ä¸­å‘ç°æ˜æ˜¾åŒ¹é…æº'ã€‚"
    }
}
"""

# -------------------------------------------------------------
# 3. å·¥å…·å‡½æ•°ï¼šæ–‡æ¡£è§£æ
# -------------------------------------------------------------
def extract_text_from_pdf(file):
    try:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        return text
    except Exception as e:
        st.error(f"PDF è§£æå¤±è´¥: {e}")
        return None

def extract_text_from_docx(file):
    try:
        doc = Document(file)
        text = ""
        for para in doc.paragraphs:
            text += para.text + "\n"
        return text
    except Exception as e:
        st.error(f"Word è§£æå¤±è´¥: {e}")
        return None

# -------------------------------------------------------------
# 4. æ¨¡å‹è°ƒç”¨å‡½æ•°
# -------------------------------------------------------------
def analyze_with_zhipu(api_key, content, is_image=False, image_data=None):
    """ä½¿ç”¨æ™ºè°± AI è¿›è¡Œåˆ†æ"""
    if not api_key:
        return {"error": "æœªæ£€æµ‹åˆ°æ™ºè°± API Keyï¼Œè¯·æ£€æŸ¥ secrets é…ç½®ã€‚"}
    
    client = ZhipuAI(api_key=api_key)
    
    try:
        if is_image and image_data:
            # å›¾ç‰‡æ¨¡å¼ (GLM-4V)
            import base64
            img_byte_arr = io.BytesIO()
            image_data.save(img_byte_arr, format='JPEG')
            img_byte_arr = img_byte_arr.getvalue()
            base64_image = base64.b64encode(img_byte_arr).decode('utf-8')
            
            response = client.chat.completions.create(
                model="glm-4v", 
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": ANALYSIS_SYSTEM_PROMPT + "\n\nè¯·åˆ†æè¿™å¼ å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ï¼š"
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ]
            )
        else:
            # æ–‡æœ¬æ¨¡å¼ (GLM-4)
            response = client.chat.completions.create(
                model="glm-4",
                messages=[
                    {"role": "system", "content": ANALYSIS_SYSTEM_PROMPT},
                    {"role": "user", "content": content}
                ],
                temperature=0.1
            )
            
        return json.loads(response.choices[0].message.content.replace('```json', '').replace('```', ''))
    
    except json.JSONDecodeError:
        return {"error": "æ¨¡å‹è¿”å›æ ¼å¼è§£æå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚"}
    except Exception as e:
        return {"error": f"æ™ºè°± API è°ƒç”¨å¤±è´¥: {str(e)}"}

def analyze_with_gemini(api_key, content, is_image=False, image_data=None):
    """ä½¿ç”¨ Google Gemini è¿›è¡Œåˆ†æ"""
    if not api_key:
        return {"error": "æœªæ£€æµ‹åˆ° Gemini API Keyï¼Œè¯·æ£€æŸ¥ secrets é…ç½®ã€‚"}
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(
            model_name='gemini-2.5-flash',
            system_instruction=ANALYSIS_SYSTEM_PROMPT,
            generation_config={"response_mime_type": "application/json"}
        )
        
        if is_image and image_data:
            response = model.generate_content([
                "è¯·åˆ†æè¿™å¼ å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ï¼Œå¹¶æŒ‰ç…§ç³»ç»Ÿæç¤ºçš„ JSON æ ¼å¼è¾“å‡ºã€‚", 
                image_data
            ])
        else:
            response = model.generate_content(content)
            
        return json.loads(response.text)
        
    except Exception as e:
        return {"error": f"Gemini API è°ƒç”¨å¤±è´¥: {str(e)}"}

# -------------------------------------------------------------
# 5. UI å¸ƒå±€ä¸ä¸»é€»è¾‘ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šç§»é™¤ä¾§è¾¹æ ï¼Œæ¨¡å‹é€‰æ‹©ç§»åˆ°ä¸»é¡µé¢ï¼‰
# -------------------------------------------------------------
# é¡µé¢æ ‡é¢˜
st.markdown('<div class="main-header">ğŸ° AIå…”å­ å†…å®¹ä¸å‰½çªƒæ£€æµ‹ç³»ç»Ÿ</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">ä¸Šä¼ æ–‡æ¡£ã€å›¾ç‰‡æˆ–è¾“å…¥æ–‡æœ¬ï¼Œä¸€é”®æ£€æµ‹ AI ç”Ÿæˆç—•è¿¹ä¸å†…å®¹å‰½çªƒé£é™©</div>', unsafe_allow_html=True)

# æ¨¡å‹é…ç½®å¡ç‰‡ï¼ˆæ›¿ä»£åŸä¾§è¾¹æ ï¼Œæ”¾åœ¨ä¸»é¡µé¢é¡¶éƒ¨ï¼‰
#st.markdown('<div class="model-config-card">', unsafe_allow_html=True)
#st.markdown("### âš™ï¸ æ¨¡å‹é…ç½®", unsafe_allow_html=True)

# æ¨¡å‹é€‰æ‹©ï¼ˆæ¨ªå‘æ’åˆ—ï¼Œæ›´ç¾è§‚ï¼‰
model_provider = st.radio(
    "é€‰æ‹©åˆ†ææ¨¡å‹",
    ("æ™ºè°± AI (é»˜è®¤)", "Google Gemini (è¿›é˜¶)"),
    captions=["å…è´¹è®¿é—®ï¼ŒGLM-4æ¨¡å‹", "å¤šæ¨¡æ€èƒ½åŠ›å¼ºï¼ŒGemini-2.5æ¨¡å‹"],
    key="model_selector"
)

st.markdown('</div>', unsafe_allow_html=True)  # å…³é—­æ¨¡å‹é…ç½®å¡ç‰‡

# è¾“å…¥æ–¹å¼é€‰é¡¹å¡
tab1, tab2, tab3 = st.tabs(["ğŸ“ æ–‡æœ¬è¾“å…¥", "ğŸ“‚ æ–‡æ¡£ä¸Šä¼  (PDF/Word)", "ğŸ–¼ï¸ å›¾ç‰‡åˆ†æ"])

content_to_analyze = ""
image_to_analyze = None
is_image_mode = False
process_trigger = False

with tab1:
    text_input = st.text_area("åœ¨æ­¤ç²˜è´´æˆ–è¾“å…¥éœ€è¦æ£€æµ‹çš„æ–‡å­—ï¼š", height=200)
    if st.button("å¼€å§‹åˆ†ææ–‡æœ¬", key="btn_text", type="primary"):
        if text_input.strip():
            content_to_analyze = text_input
            process_trigger = True
        else:
            st.warning("è¯·è¾“å…¥æ–‡å­—ã€‚")

with tab2:
    uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡£", type=['pdf', 'docx'])
    if st.button("å¼€å§‹åˆ†ææ–‡æ¡£", key="btn_doc", type="primary"):
        if uploaded_file:
            with st.spinner("æ­£åœ¨è§£ææ–‡æ¡£..."):
                if uploaded_file.name.endswith('.pdf'):
                    content_to_analyze = extract_text_from_pdf(uploaded_file)
                elif uploaded_file.name.endswith('.docx'):
                    content_to_analyze = extract_text_from_docx(uploaded_file)
                
                if content_to_analyze and len(content_to_analyze) > 10:
                    process_trigger = True
                    st.success(f"æ–‡æ¡£è§£ææˆåŠŸï¼å…± {len(content_to_analyze)} å­—ã€‚")
                else:
                    st.error("æ–‡æ¡£è§£æå¤±è´¥æˆ–å†…å®¹ä¸ºç©ºã€‚")
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ã€‚")

with tab3:
    uploaded_image = st.file_uploader("ä¸Šä¼ åŒ…å«æ–‡å­—çš„å›¾ç‰‡", type=['png', 'jpg', 'jpeg'])
    if uploaded_image:
        image_to_analyze = Image.open(uploaded_image)
        st.image(image_to_analyze, caption="é¢„è§ˆå›¾ç‰‡", use_container_width=True)
        if st.button("å¼€å§‹åˆ†æå›¾ç‰‡", key="btn_img", type="primary"):
            is_image_mode = True
            process_trigger = True

# --- æ‰§è¡Œåˆ†æ ---
if process_trigger:
    # æ ¹æ®é€‰æ‹©è‡ªåŠ¨è·å– Key
    current_api_key = None
    try:
        if "Gemini" in model_provider:
            current_api_key = st.secrets["GEMINI_API_KEY"]
        else:
            current_api_key = st.secrets["ZHIPU_API_KEY"]
    except KeyError as e:
        st.error(f"âŒ ç¼ºå°‘é…ç½®ï¼šæœªåœ¨ Secrets ä¸­æ‰¾åˆ° {e}ã€‚è¯·åœ¨ .streamlit/secrets.toml ä¸­é…ç½®ã€‚")
        st.stop()
    except FileNotFoundError:
        st.error("âŒ é…ç½®æ–‡ä»¶ä¸¢å¤±ï¼šæœªæ‰¾åˆ° .streamlit/secrets.toml æ–‡ä»¶ã€‚")
        st.stop()

    result_container = st.container()
    
    with st.spinner(f"æ­£åœ¨è°ƒç”¨ {'Gemini' if 'Gemini' in model_provider else 'æ™ºè°±AI'} è¿›è¡Œæ·±åº¦åˆ†æ..."):
        start_time = time.time()
        
        # é€‰æ‹©æ¨¡å‹è°ƒç”¨
        if "Gemini" in model_provider:
            result = analyze_with_gemini(current_api_key, content_to_analyze, is_image_mode, image_to_analyze)
        else:
            result = analyze_with_zhipu(current_api_key, content_to_analyze, is_image_mode, image_to_analyze)
        
        end_time = time.time()

    # --- ç»“æœå±•ç¤º ---
    if "error" in result:
        st.error(result["error"])
    else:
        st.toast(f"åˆ†æå®Œæˆï¼è€—æ—¶ {end_time - start_time:.2f} ç§’")
        
        # è§£æç»“æœ
        ai_data = result.get("ai_detection", {})
        copy_data = result.get("plagiarism_detection", {})
        
        # 1. AI æ£€æµ‹ç»“æœå±•ç¤º
        st.markdown("### ğŸ¤– ç»´åº¦ä¸€ï¼šAI ç”Ÿæˆæ£€æµ‹")
        col1, col2 = st.columns([1, 2])
        
        with col1:
            score = ai_data.get("score", 0)
            label = ai_data.get("label", "æœªçŸ¥")
            
            # åŠ¨æ€é¢œè‰²
            color = "green"
            if score > 40: color = "orange"
            if score > 80: color = "red"
            
            st.markdown(f"""
            <div style="text-align: center; padding: 20px; border: 2px solid {color}; border-radius: 10px;">
                <h2 style="color: {color}; margin: 0;">{label}</h2>
                <h1 style="font-size: 3rem; margin: 0;">{score}%</h1>
                <p style="color: #666;">AI ç–‘ä¼¼åº¦</p>
            </div>
            """, unsafe_allow_html=True)
            
        with col2:
            st.markdown('<div class="result-card">', unsafe_allow_html=True)
            st.markdown(f"**åˆ¤å®šç†ç”±ï¼š**\n\n{ai_data.get('reason', 'æ— è¯¦ç»†ç†ç”±')}")
            st.progress(score / 100)
            st.markdown('</div>', unsafe_allow_html=True)

        st.markdown("---")

        # 2. å‰½çªƒæ£€æµ‹ç»“æœå±•ç¤º
        st.markdown("### ğŸ“ ç»´åº¦äºŒï¼šå‰½çªƒ/æŠ„è¢­æ£€æµ‹")
        col3, col4 = st.columns([1, 2])
        
        with col3:
            copy_score = copy_data.get("percentage", 0)
            
            # åŠ¨æ€é¢œè‰²
            copy_color = "green"
            if copy_score > 20: copy_color = "orange"
            if copy_score > 50: copy_color = "red"
            
            st.markdown(f"""
            <div style="text-align: center; padding: 20px; border: 2px solid {copy_color}; border-radius: 10px;">
                <h2 style="color: {copy_color}; margin: 0;">å‰½çªƒé£é™©</h2>
                <h1 style="font-size: 3rem; margin: 0;">{copy_score}%</h1>
                <p style="color: #666;">é‡å¤ç‡é¢„ä¼°</p>
            </div>
            """, unsafe_allow_html=True)
            
        with col4:
            st.markdown('<div class="result-card">', unsafe_allow_html=True)
            st.markdown(f"**åˆ†æè¯¦æƒ…ï¼š**\n\n{copy_data.get('reason', 'æ— è¯¦ç»†ç†ç”±')}")
            st.markdown(f"**ğŸ“š å¯èƒ½æ¥æºï¼š**\n\n{copy_data.get('sources', 'æœªçŸ¥')}")
            st.markdown('</div>', unsafe_allow_html=True)
        
        # 3. åŸå§‹æ•°æ®ï¼ˆè°ƒè¯•ç”¨ï¼‰
        with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹ JSON æ•°æ®"):
            st.json(result)

        st.markdown("""
        <div class="warning-text">
        âš ï¸ å…è´£å£°æ˜ï¼šæœ¬å·¥å…·æ£€æµ‹ç»“æœåŸºäºå¤§æ¨¡å‹æ¦‚ç‡é¢„æµ‹ï¼Œä»…ä¾›å‚è€ƒï¼Œä¸ä½œä¸ºæœ€ç»ˆçš„å­¦æœ¯æˆ–æ³•å¾‹ä¾æ®ã€‚
        AI æ¨¡å‹å¯èƒ½ä¼šäº§ç”Ÿå¹»è§‰ï¼ˆHallucinationï¼‰ï¼Œå¯¹äºå‰½çªƒæ¥æºçš„å¼•ç”¨è¯·åŠ¡å¿…è¿›è¡Œäººå·¥æ ¸å®ã€‚
        </div>
        """, unsafe_allow_html=True)
# æ–¹æ¡ˆ1ï¼šæ”¹ç”¨ Streamlit State + äº‘ç«¯æ•°æ®åº“ï¼ˆæ¨èï¼‰
# éœ€å…ˆå®‰è£…ï¼špip install streamlit-extras
from streamlit_extras import session_state
import sqlite3

# åˆå§‹åŒ–SQLiteæ•°æ®åº“ï¼ˆäº‘ç«¯æŒä¹…åŒ–ï¼‰
conn = sqlite3.connect("visit_stats.db", check_same_thread=False)
c = conn.cursor()
c.execute('''CREATE TABLE IF NOT EXISTS visits 
             (date TEXT PRIMARY KEY, count INTEGER)''')
conn.commit()

def update_daily_visits_cloud():
    today_str = datetime.date.today().isoformat()
    if "has_counted" in st.session_state:
        c.execute("SELECT count FROM visits WHERE date=?", (today_str,))
        res = c.fetchone()
        return res[0] if res else 0
    
    # æ›´æ–°æ•°æ®åº“è®¡æ•°
    c.execute("SELECT count FROM visits WHERE date=?", (today_str,))
    res = c.fetchone()
    count = res[0] + 1 if res else 1
    c.execute("REPLACE INTO visits (date, count) VALUES (?, ?)", (today_str, count))
    conn.commit()
    
    st.session_state["has_counted"] = True
    return count

daily_visits = update_daily_visits_cloud()

# ä½¿ç”¨æ‰©å±•è®¡æ•°
st.markdown(f"ä»Šæ—¥è®¿é—®ï¼š{daily_visits} | æ€»è®¿é—®ï¼š{daily_visits} | ç‹¬ç«‹è®¿å®¢ï¼š{daily_visits}", unsafe_allow_html=True)


# ä½¿ç”¨æ‰©å±•è®¡æ•°
#daily, total, uv = update_visit_stats()
#st.markdown(f"ä»Šæ—¥è®¿é—®ï¼š{daily} | æ€»è®¿é—®ï¼š{total} | ç‹¬ç«‹è®¿å®¢ï¼š{uv}", unsafe_allow_html=True)

